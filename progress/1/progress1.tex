\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[catalan]{babel}
\usepackage[vmargin=3cm]{geometry}
\usepackage{lastpage}
\usepackage{lipsum}
\usepackage{graphicx}
\usepackage{parskip}
\usepackage{hyperref}
\usepackage{url}
\usepackage{caption}
\usepackage{listings}

\usepackage{silence}
\WarningFilter{latex}{You have requested package}
\usepackage{../../common/listings-rust}

\Urlmuskip=0mu plus 2mu

\hypersetup{
    colorlinks=true,
    linkcolor=black,
    urlcolor=blue,
    citecolor=red,
}

\graphicspath{ {images/} }

\lstnewenvironment{code}[1][]{
   \noindent
   \lstset{
        language=Rust,
        style=colouredRust,
        inputencoding=latin1
    }
}{}

\begin{document}
\begin{titlepage}
	\newcommand{\HRule}{\rule{\linewidth}{0.4mm}} % Defines a new command for horizontal lines, change thickness here
	
	\center

    \vspace*{25px}
    % == Headings ==
	
	\textsc{\LARGE Universitat Autònoma de Barcelona}\\[1.5cm]

	\textsc{\Large Treball de Fi de Grau}\\[0.5cm]
	
	\textsc{\Large Informe de progrés I}\\[0.5cm]
	
	\HRule\\[0.4cm]
	
	{\LARGE\bfseries Disseny i implementació d'un llenguatge de programació amb LLVM}\\[0.4cm]
	
	\HRule\\[1.5cm]
	
	% == Author ==
	
	\begin{minipage}{0.5\textwidth}
		\begin{flushleft}
			\large
			\textit{Autor}\\
			\textsc{Josep Maria Domingo Catafal}
		\end{flushleft}
	\end{minipage}
	~
	\begin{minipage}{0.4\textwidth}
		\begin{flushright}
			\large
			\textit{Tutor}\\
			\textsc{Javier Sánchez Pujadas}
		\end{flushright}
	\end{minipage}
	
	% == Date == 

	\vfill\vfill\vfill % Position the date 3/4 down the remaining page
	
	{\large\today} % Date, change the \today to a set date if you want to be precise

	\vfill % Push the date up 1/4 Of the remaining page
\end{titlepage}

% --------------------------------------
% Table of contents
% --------------------------------------
\tableofcontents
\newpage

% --------------------------------------
% Body
% --------------------------------------
\section{Metodologia}
Per tal d'organitzar el projecte es va optar per una metodologia Agile/Scrum
però adaptada per a una sola persona. Principalment consisteix a crear esprints
d'una setmana. Un esprint és simplement un bloc de temps (una setmana en el
nostre cas) en el que s'han de completar un seguit de tasques. Les tasques han
de ser petites per tal d'oferir la màxima flexibilitat i s'agrupen en èpiques.
Les èpiques ens indiquen una funcionalitat que ha de tenir el llenguatge, i
totes les tasques que la conformen són les tasques necessàries per poder
desenvolupar aquesta funcionalitat.

\subsection{Eines}
Tot i ser un projecte de no gran envergadura, i format només per una persona, és
difícil organitzar-se sense fer ús de cap eina. És per això que s'han utilitzat
principalment dues eines: una per gestionar les tasques i els terminis, i un
altre per gestionar el control de versions del codi font.

\subsubsection{Gestió de les tasques} Per crear i gestionar les tasques s'ha
estat fent servir Jira, com vam comentar en el primer informe. Es va triar
aquesta eina, ja que l'he fet servir prèviament en projectes professionals i ja
la tenia per mà. Permet crear tasques i assignar-les a esprints, a més de crear
un roadmap amb les èpiques, mostrant de manera gràfica quan inicien i quan han
d'acabar. També té moltes funcions de mètriques, tot i que no es faran servir en
aquest projecte.

En el temps que ha transcorregut des de l'inici, està funcionant realment bé, i
ajuda bastant en l'organització.

\subsubsection{Control de versions del codi font} L'altra eina important és el
control de versions. És imprescindible, des del meu punt de vista, si has de
col·laborar amb més gent, però també, en projectes com aquest que són
individuals. Et permet estar al cas de tots els canvis que has fet en el
projecte, i en casos que trobis un bug, és molt més fàcil tirar enrere en el
temps per trobar on va aparèixer per primer cop.

De totes les eines de control de versions, s'està fent servir Git, ja que és
l'estàndard en el desenvolupament del software i és amb la que estic més 
familiaritzat. També s'està fent servir GitHub per allotjar el repositori, ja 
que ofereix moltes funcionalitats i a més és on es troben la gran majoria de
projectes de codi obert i disposa d'una gran comunitat.

\section{Seguiment de la planificació}

Si recordem, a l'inici del treball vam definir quines eren les èpiques que
conformarien el projecte i en quin moment es desenvoluparien. A hores d'ara
aquestes èpiques segueixen més o menys com s'havien plantejat al seu moment,
però amb algun canvi pel que fa al moment en el qual s'han desenvolupat (alguna
ha durat més de l'esperat). També s'ha creat una nova èpica per albergar tots
els bugs i tasques de manteniment i millora del projecte que van apareixent a
mesura que va avançant. 

A continuació mirarem aquestes èpiques, una per una, per veure quin és el seu
estat, i, per les que ja s'han completat, donar una mica més de detall de què
han aportat al projecte i com s'han desenvolupat a un nivell més tècnic.


\subsection{Implementació mínima de l'especificació}
\textit{\textbf{Completada}: 13/09/2022 - 16/10/2022} (5 esprints)

Aquesta èpica és la primera que es va completar i de la qual neixen la resta.
Consistia en la creació d'una base sòlida del llenguatge que permetés crear
programes simples amb operacions numèriques i control de flux.

Aquesta èpica és la més llarga de totes, ja que requereix molta feina inicial.
Va acabar una setmana més tard del previst, però tot i això no ha tingut gaire
afectació al conjunt del projecte.

El primer que es va fer va ser crear el projecte i un conjunt de funcions
d'utilitat. El projecte es divideix principalment en 4 mòduls:

\subsubsection{Mòdul principal}
S'encarrega de gestionar l'entrada de l'usuari (per exemple llegir l'arxiu a
compilar) i crida a la resta de mòduls, passant la  sortida d'un a l'entrada del
següent. Bàsicament és el conductor de la resta de mòduls.

\subsubsection{Lexer}
Aquest mòdul s'encarrega de llegir la seqüència de caràcters del codi a compilar
i transformar-lo en un conjunt de tokens. Principalment ens permet identificar
els símbols del llenguatge i alertar a l'usuari en cas que n'estigui fent servir
algun que no és vàlid. La manera com funciona és la següent:

Mentre que no hàgim arribat al final de la seqüència de caràcters, processem el
següent caràcter en la seqüència. 

Si és un parèntesi, per exemple, com que per si sol forma una seqüència vàlida,
i no pot generar-ne cap altre, creem un nou token de tipus parèntesis i l'afegim
al conjunt de sortida. Si per contra ens trobéssim un caràcter tipus '>', no
podem crear un token encara, ja que depenent del següent caràcter, podria ser un
'>=' o bé un '>'. Per tant, escanegem també el següent caràcter i en funció
d'això creem el token. 

Un cas particular que poder cal destacar, és quan ens trobem amb
un caràcter alfanumèric, ja que hem de tenir en compte més coses:

\begin{itemize}
\item
    Si és un dígit, vol dir que estem processant un nombre, i per tant hem
    d'anar avançant mentre ens anem trobant dígits. Mentre processem els dígits
    pot ser que ens trobem una coma, el que ens indicarà que és un nombre real i
    per tant generarem un token de float. Si, no té coma en canvi, generem un
    token d'int.
\item
    Si en canvi és un caràcter alfabètic, haurem d'anar avançant mentre que ens
    trobem caràcters alfanumèrics (no es permeten dígits a l'inici d'un
    identificador però si a la meitat) o guions baixos. Un cop troben un altre
    tipus de caràcter, vol dir que ja hem acabat i podem crear el token. Ara bé,
    aquest token pot ser un identificador o una paraula reservada del
    llenguatge, per tant, hem de comprovar si és una paraula reservada i crear
    un token o l'altre en funció d'això.
\end{itemize}

En general el lexer, un cop fet no s'haurà de modificar gaire, només caldrà
modificar-lo si hem d'afegir alguna paraula reservada nova el llenguatge o algun
símbol nou i que per tant no reconeix encara.

\subsubsection{Parser}

El lexer ens ha permès identificar els símbols del programa, però no ens permet
identificar si l'ordre és correcte o si segueix les normes del llenguatge (és a
dir si és gramaticalment correcte). Aquesta és la funció del parser, el qual a
partir de la seqüència de tokens, n'extraurà el significat i generarà un arbre
sintàctic, el qual ens indica com haurem d'executar les instruccions.

La funció del parser és fer complir la gramàtica del llenguatge. S'ha
implementat en la forma d'un \textit{recursive descent parser} el qual és
pràcticament una traducció literal de la gramàtica en forma de codi.

El que fa el parser és començar pel primer token de la seqüència que ens ha
generat el lexer. A partir d'allà va descendint de forma recursiva per totes les
produccions de la gramàtica. Per exemple, si el primer token és 'fn', el parser
començarà a explorar la producció que genera una funció. Mirarà que seguidament
de 'fn' hi hagi un identificar. Si no hi és, es retorna un error a l'usuari. Si
hi és, aleshores segueix descendint, mira que s'especifiquin correctament els
paràmetres, si hi són, el valor de retorn i finalment el cos de la funció. Diem
que és recursiu perquè pot ser que mentre estem generant, per exemple una
expressió, pot ser que aquesta estigui formada per altres expressions, i per
tant, tornarà a cridar de forma recursiva la producció d'expressió.

Posem un exemple més il·lustratiu, amb una petita gramàtica, i com aquesta
s'implementaria en el parser. Aquesta seria la gramàtica per generar el
prototipus d'una funció (excloem el tipus de retorn de la funció, que aniria
després dels paràmetres, per simplificar):

\begin{verbatim}
<prototype>  ::= fn <id> "(" <params> ")"
<id>         ::= letter { letter | digit | "_" }
<params>     ::= "(" { <param> { , <param> } } ")"
<param>      ::= <id>: <type>
\end{verbatim}

La implementació d'aquesta gramàtica seria de la següent manera (en un
pseudocodi aproximat a Rust):

\begin{code}
fn parse_prototype() -> (Prototype, Err) {
    // we expect to find the fn keyword, else it's an error
    match current_token().kind {
        // The advance function moves to the next token
        TokenKind::Fn => advance(),
        _ => return Err("Expected fn keyword"),
    };

    // we expect to find the function name, else it's an error
    let name = match current_token().kind {
        TokenKind::Identifier => current_token().lexeme,
        _ => return Err("Expected an identifier"),
    };

    advance();

    // we call the params rule
    let params = parse_params();

    // we are done, we return a struct with the info of the prototype
    return Prototype { 
        name,
        params,
    };
}
\end{code}

És així de simple, iterem els tokens un per un i comprovem que el token que
estem revisant sigui el token que esperem trobar, en funció del que ens diu la
gramàtica. I quan el que esperen és una altra producció, simplement cridem a la
funció que implementa aquesta producció. En el nostre exemple la funció
\texttt{parse\_params}:

\begin{code}
    fn parse_params() -> (Vec<Variable>, Err) {
        // params start with an opening paren, else it's an error
        match current_token().kind {
            TokenKind::LeftParen => advance(),
            _ => return Err("Expected left paren"),
        };

        // if we find a closing paren, then we are done (no params)
        if current_token().kind == TokenKind::RightParen {
            advance();
            return [];
        }

        let params = [];

        loop {
            // we expect an identifier for the param name
            let name = match current_token().kind {
                TokenKind::Identifier => current_token().lexeme,
                _ => return Err("Expected an identifier"),
            };

            advance();

            // a colon separates the identifier from the type
            match current_token().kind {
                TokenKind::Colon => advance(),
                _ => return Err("Expected ':' after identifier"),
            };

            // finally the type
            let type = match current_token().kind {
                TokenKind::Identifier => current_token().lexeme,
                _ => return Err("Expected an identifier"),
            };

            // add it to the list of params
            params.push(Param { name, type });

            advance();

            match current_token().kind {
                // if it's a ')' we are done and we break from the loop
                TokenKind::RightParen => {
                    advance();
                    break;
                }
                // if it's a ',' then there's another param
                TokenKind::Comma => advance(),
                // else it's an error
                _ => return Err("Expected right paren or comma"),
            }
        }
    }
\end{code}

\subsubsection{Anàlisi semàntica i generació de codi}
En la definició del projecte vam comentar que fariem servir LLVM. Ara entrarem
en una mica més de detall per veure que és LLVM, com funciona i com ha estat
incorporat al projecte per tal de generar el codi.

LLVM va ser creat el 2003 per Chris Lattner (també creador del llenguatge de
programació Swift) i disposa del suport d'empreses com Apple (LLVM és una part
integral de XCode i de Swift per al desenvolupament d'aplicacions iOS), Google,
IBM o Intel. Actualment hi ha diversos dels principals llenguatges de
programació que en fan ús com ara C/C++ (a través del compilador Clang, una
alternativa a GCC), Rust o Swift.

LLVM és un toolchain per crear compiladors, és a dir que té moltes eines diferents
que ens ajuden en la implementació de compiladors, però principalment, i el que
ens interessa a nosaltres, és un back end (de fet n'és molts a la vegada com ja
veurem). Un back end és la part del compilador que genera assemblador per alguna
arquitectura en concret a partir d'una representació intermèdia. Ara bé, en el
cas de LLVM, no genera assemblador per una arquitectura en concret, sino que en
genera per pràcticament totes les arquitectures disponibles actualment.
D'aquesta manera, tu, com a creador de llenguatges de programació, només t'has
de preocupar de generar la representació intermèdia de LLVM. A partir d'aquí hi
aplicarà optimitzacions i generarà l'assemblador de l'arquitectura que l'hi
indiquis. Fins i tot pot generar Web Assembly, cosa que ens permet executar el
llenguatge en navegadors web moderns.

Donat que LLVM és independent de l'arquitectura, quan generem el codi, no ens
hem de preocupar del nombre de registres, ja que disposen d'un nombre il·limitat
de registres virtuals, els quals LLVM mapejarà posteriorment als registres de
l'arquitectura corresponent.

Com hem comentat, LLVM també aplica optimitzacions al codi generat, com pot ser
eliminar codi que no es fa servir o avaluar expressions que es poden saber en
temps de compilació. Ara bé, perquè LLVM pugui fer aquestes optimitzacions, 
nosaltres haurem de generar el codi en SSA (Static single-assignment), el que vol
dir que només podem assignar valor a una variable una vegada. Si necessitem 
reassignar un valor, hem de crear una nova variable que la substitueixi. Això es
fa simplement perquè facilita molt a l'hora d'aplicar optimitzacions.



\subsection{Declaració de tipus}
\textit{\textbf{Completada}: 17/10/2022 - 6/11/2022} (3 esprints)

L'objectiu d'aquesta èpica era permetre a l'usuari definir tipus propis a part
dels que venen per defecte en el llenguatge. Aquest objectiu s'ha traduït en la
implementació de structs dins del llenguatge, el qual permet definir conjunts de
dades de forma estructurada. Funcionen igual que els structs de C, per exemple.
La intenció es afegir mètodes als structs, per així poder dotar-los de
funcionalitat, similar a les classes d'altres llenguatges, però això es farà més
endavant si dona temps, ja que no és una funcionalitat imprescindible, donat que
es pot obtenir un funcionament similar al dels mètodes, passant els structs com
a paràmetre a les funcions.

Implementar els structs, com la gran majoria de noves funcionalitats afegides al
llenguatge implica modificar el lexer, el parser i la generació de codi. 

En quant al lexer no implica gaires complicacions. Simplement afegim una nova
paraula clau ("struct") i també perque detecti els punts com a caràcter vàlid,
ja que per accedir al camp d'un struct fem \texttt{struct.camp}.

Ampliar el parser, requereix una mica més de feina, però no difereix gaire del
que hem fet fins ara. Hem d'implementar en el parser les produccions per a la
definició de structs, per la instanciació i per l'accés als camps.

La part més complexa és la de generació de codi, ja que hem de tenir en compte
la distribució de les dades en la memòria. Donat que podem tenir tres tipus
diferents d'interaccions amb els structs els analitzarem per separat.

\begin{itemize}
\item \textbf{Definició}: Els structs en LLVM són simplement un conjunt
    de dades de diferents tipus una rere l'altre. Per exemple, el struct:

    \begin{code}
        struct {
            first: i64
            second: f64
        }
    \end{code}

    es representa de la següent manera:

    \begin{code}
        struct { i64, f64 }
    \end{code}

    Només indiquem els tipus dels camps i en quin ordre van, però no hi ha cap
    identificador. Per aquest motiu, es responsabilitat nostra, comprovar coses
    com ara que un camp no estigui duplicat, o saber en quina posició del struct
    es troba la dada que ens demana l'usuari a través de l'identificador. Per
    tant, durant el procés de compilació hem de guardar totes les definicions
    dels structs, els seus camps, i l'ordre en el qual es troben.
\end{itemize}

\subsection{Collections}
\textit{\textbf{En progrés}: 31/10/2022 - 20/11/2022*} (3 esprints)

Implementació d'arrays estàtics, arrays dinàmics i tuples.

\subsection{Mecanisme de gestió d'errors}
Implementar un mecanisme per tal de gestionar errors en temps d'execució.

\subsection{Syntactic sugar}
Implementació de "Syntactic sugar", per tal de simplificar operacions que
s'utilitzen freqüentment. Inclou bucles for in, match (similar a un switch),
list comprehension, etc.

\subsection{Suport per programació d'estil funcional}
Afegir suport per programació d'estil funcional, integrant funcions com ara map,
reduce, fold, etc.

\section{Passos a seguir}

\begin{thebibliography}{9}

\bibitem{repo} Codi del projecte, \url{https://github.com/josepmdc/craft}

\end{thebibliography}
\end{document}
